{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 6s 0us/step\n",
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 4,200,842\n",
      "Trainable params: 4,200,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "40000/40000 [==============================] - 49s 1ms/step - loss: 1.8135 - accuracy: 0.3640 - val_loss: 1.4283 - val_accuracy: 0.4983\n",
      "Epoch 2/20\n",
      "40000/40000 [==============================] - 48s 1ms/step - loss: 1.4161 - accuracy: 0.4993 - val_loss: 1.2886 - val_accuracy: 0.5522\n",
      "Epoch 3/20\n",
      "40000/40000 [==============================] - 48s 1ms/step - loss: 1.2861 - accuracy: 0.5497 - val_loss: 1.2202 - val_accuracy: 0.5776\n",
      "Epoch 4/20\n",
      "40000/40000 [==============================] - 48s 1ms/step - loss: 1.1962 - accuracy: 0.5785 - val_loss: 1.1619 - val_accuracy: 0.6004\n",
      "Epoch 5/20\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 1.1279 - accuracy: 0.6033 - val_loss: 1.1058 - val_accuracy: 0.6156\n",
      "Epoch 6/20\n",
      "40000/40000 [==============================] - 58s 1ms/step - loss: 1.0675 - accuracy: 0.6241 - val_loss: 1.1410 - val_accuracy: 0.6096\n",
      "Epoch 7/20\n",
      "40000/40000 [==============================] - 48s 1ms/step - loss: 1.0184 - accuracy: 0.6437 - val_loss: 1.0602 - val_accuracy: 0.6314\n",
      "Epoch 8/20\n",
      "40000/40000 [==============================] - 48s 1ms/step - loss: 0.9720 - accuracy: 0.6558 - val_loss: 1.0694 - val_accuracy: 0.6342\n",
      "Epoch 9/20\n",
      "40000/40000 [==============================] - 49s 1ms/step - loss: 0.9326 - accuracy: 0.6746 - val_loss: 1.0105 - val_accuracy: 0.6559\n",
      "Epoch 10/20\n",
      "40000/40000 [==============================] - 48s 1ms/step - loss: 0.8960 - accuracy: 0.6878 - val_loss: 1.0183 - val_accuracy: 0.6489\n",
      "Epoch 11/20\n",
      "40000/40000 [==============================] - 50s 1ms/step - loss: 0.8563 - accuracy: 0.7010 - val_loss: 1.0082 - val_accuracy: 0.6570\n",
      "Epoch 12/20\n",
      "40000/40000 [==============================] - 58s 1ms/step - loss: 0.8300 - accuracy: 0.7084 - val_loss: 1.0592 - val_accuracy: 0.6369\n",
      "Epoch 13/20\n",
      "40000/40000 [==============================] - 48s 1ms/step - loss: 0.8009 - accuracy: 0.7218 - val_loss: 1.0606 - val_accuracy: 0.6494\n",
      "Epoch 14/20\n",
      "40000/40000 [==============================] - 48s 1ms/step - loss: 0.7720 - accuracy: 0.7317 - val_loss: 1.0780 - val_accuracy: 0.6441\n",
      "Epoch 15/20\n",
      "40000/40000 [==============================] - 49s 1ms/step - loss: 0.7421 - accuracy: 0.7444 - val_loss: 1.0103 - val_accuracy: 0.6693\n",
      "Epoch 16/20\n",
      "40000/40000 [==============================] - 48s 1ms/step - loss: 0.7215 - accuracy: 0.7517 - val_loss: 1.0112 - val_accuracy: 0.6677\n",
      "Epoch 17/20\n",
      "40000/40000 [==============================] - 51s 1ms/step - loss: 0.7043 - accuracy: 0.7548 - val_loss: 1.1620 - val_accuracy: 0.6396\n",
      "Epoch 18/20\n",
      "40000/40000 [==============================] - 57s 1ms/step - loss: 0.6771 - accuracy: 0.7653 - val_loss: 1.0332 - val_accuracy: 0.6596\n",
      "Epoch 19/20\n",
      "40000/40000 [==============================] - 48s 1ms/step - loss: 0.6645 - accuracy: 0.7707 - val_loss: 1.0357 - val_accuracy: 0.6689\n",
      "Epoch 20/20\n",
      "40000/40000 [==============================] - 48s 1ms/step - loss: 0.6401 - accuracy: 0.7781 - val_loss: 1.0764 - val_accuracy: 0.6488\n",
      "10000/10000 [==============================] - 5s 487us/step\n",
      "Test score: 1.0825746486663819\n",
      "Test accuracy: 0.6380000114440918\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10 \n",
    "from keras.utils import np_utils \n",
    "from keras.models import Sequential \n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D \n",
    "from keras.optimizers import SGD, Adam, RMSprop \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# CIFAR_10 is a set of 60K images 32x32 pixels on Flatten 3 channels\n",
    "IMG_CHANNELS = 3 \n",
    "IMG_ROWS = 32 \n",
    "IMG_COLS = 32 \n",
    "\n",
    "#constant \n",
    "BATCH_SIZE = 128 \n",
    "NB_EPOCH = 20 \n",
    "NB_CLASSES = 10 \n",
    "VERBOSE = 1 \n",
    "VALIDATION_SPLIT = 0.2 \n",
    "OPTIM = RMSprop() \n",
    "#load dataset \n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data() \n",
    "print('X_train shape:', X_train.shape) \n",
    "print(X_train.shape[0], 'train samples') \n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert to categorical \n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES) \n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES) \n",
    "\n",
    "# float and normalization \n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32') \n",
    "X_train /= 255 \n",
    "X_test /= 255\n",
    "\n",
    "# network \n",
    "model = Sequential() \n",
    "model.add(Conv2D(32, (3, 3), padding='same', \n",
    "                 input_shape=(IMG_ROWS, IMG_COLS, IMG_CHANNELS))) \n",
    "model.add(Activation('relu')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(512)) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(NB_CLASSES)) \n",
    "model.add(Activation('softmax')) \n",
    "model.summary()\n",
    "\n",
    "# train \n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIM, \n",
    "              metrics=['accuracy']) \n",
    "model.fit(X_train, Y_train, batch_size=BATCH_SIZE, \n",
    "          epochs=NB_EPOCH, validation_split=VALIDATION_SPLIT, \n",
    "          verbose=VERBOSE) \n",
    "score = model.evaluate(X_test, Y_test, \n",
    "                       batch_size=BATCH_SIZE, verbose=VERBOSE) \n",
    "print(\"Test score:\", score[0]) \n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "#save model \n",
    "model_json = model.to_json() \n",
    "\n",
    "open('cifar10_architecture.json', 'w').write(model_json) \n",
    "#And the weights learned by our deep network on the training set\n",
    "model.save_weights('cifar10_weights.h5', overwrite=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm can be used to distinguish various objects automatically, such as physical objects, animals, and persons. Each of these options present unique ethical and privacy concerns. For example, the forest service may want to use cameras to track and count various different animals on their land, or look for endangered animals. A store may be able to identify what items customers spend more time viewing. This data will be used to better design the store to influence customers to spend more time in it and therefore purchase more items. Law enforcement agencies are also using facial recognition technology to identify citizens and possibly find individuals with warrants (Almeida et al., 2021). There are many ethical and privacy concerns with this controversial technology in all fields, including law enforcement. One big concern is the accuracy of the technology. If a law enforcement officer is arresting somebody based on the inaccurate recognition software, then that can cause additional legal issues. Facial recognition technology has been shown to have issues with racial bias, where it is not as accurate for dark skinned individuals due to less training on persons of color. A study showed that facial recognition technology showed racial bias in 189 algorithms toward women of color specifically(Gangarapu, n.d.). This can cause discrimination in the technology used by law enforcement. Another significant concern is the privacy of facial recognition data and individuals likeness being stored without their consent. This likeness can be used to create fraudulent images of the individual, often referred to as deep-fakes, if not properly secured.\n",
    "\n",
    "\n",
    "\n",
    "Almeida, D., Shmarko, K., & Lomas, E. (2021). The ethics of facial recognition technologies, surveillance, and accountability in an age of artificial intelligence: a comparative analysis of US, EU, and UK regulatory frameworks. AI And Ethics, 2(3), 377–387. https://doi.org/10.1007/s43681-021-00077-w\n",
    "\n",
    "Gangarapu, K. R. (n.d.). Ethics of Facial Recognition: key issues and solutions. https://learn.g2.com/ethics-of-facial-recognition\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
